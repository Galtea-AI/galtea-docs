---
title: "Contextual Recall"
description: "Assesses how comprehensively the retrieved context covers the information needed to produce the expected output."
---

The **Contextual Recall** metric is one of several [non-deterministic Metric Types](/concepts/metric-type) Galtea uses to evaluate whether the information retrieved by your RAG pipeline sufficiently covers the knowledge needed to produce the correct or expected output. It measures completeness rather than ranking.

This metric is valuable for identifying retrieval gaps—cases where important information was missing from the context entirely.

---

## Evaluation Parameters

To compute the `contextual_recall` metric, the following inputs are required:

- **`input`**: The user's query.
- **`retrieval_context`**: The set of documents or nodes retrieved by the system.
- **`expected_output`**: The reference or target response that should be generated.

---

## How Is It Calculated?

The score is computed using an LLM that:

1. **Information Need Inference**: Determines what key facts or concepts are necessary to produce the `expected_output`.
2. **Coverage Check**: Verifies whether those pieces of information exist in the `retrieval_context`.

The metric is calculated as:

$$
\text{Contextual Recall} = \frac{\text{Number of Attributable Statements}}{\text{Total number of expressed statements}}
$$

Higher scores reflect better recall—i.e., the retriever captured all necessary supporting information.

<Note>This metric was incorporated to the Galtea platform from the open source library [deepeval](https://deepeval.com/), for more information you can also visit their [documentation](https://deepeval.com/docs/metrics-contextual-recall).</Note>


---

## Related Topics

- [Contextual Precision](/concepts/metric-type/contextual-precision)
- [Faithfulness](/concepts/metric-type/faithfulness)