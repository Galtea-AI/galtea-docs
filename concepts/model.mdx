---
title: "Model"
description: "A representation of a LLM Model with cost information to calculate cost estimations"
icon: "microchip"
iconType: "solid"
---

import ModelCard from '/snippets/cards/model-card.mdx';

## What is a Model?

A model in Galtea represents a Large Language Model (LLM) configuration with associated cost information. This allows the platform to track, estimate, and report on the costs of using different LLMs across your products and evaluations.

<Info>
  Models are organization-wide and can be referenced across multiple products to ensure consistent cost tracking.
</Info>

You can view and manage your models on the [Galtea dashboard](https://platform.galtea.ai/models).

## Use Cases for Models

Models in Galtea are primarily used for:

<CardGroup cols={2}>
  <Card title="Cost Tracking" icon="money-bill-trend-up">
    Monitor spending on AI models across different products and versions
  </Card>
  <Card title="Budget Planning" icon="chart-line">
    Project future costs based on token usage patterns
  </Card>
  <Card title="Cost Optimization" icon="sliders">
    Compare costs between different model providers and configurations
  </Card>
  <Card title="Financial Reporting" icon="file-invoice-dollar">
    Generate accurate reports on LLM usage expenses
  </Card>
</CardGroup>

## Model Properties

When creating a model in Galtea, you'll need to provide the following information:

<ResponseField name="Name" type="Text" required>
  The name of the model. This should be descriptive and indicate the provider and version.
  **Example**: "GPT-4 Turbo" or "Claude 3 Haiku"
</ResponseField>

<ResponseField name="Cost per Input Token" type="Number" required>
  The cost in dollars per input token. This is the rate charged by the provider for tokens in your prompts.
  **Example**: 0.00001 (representing $0.00001 per token)
</ResponseField>

<ResponseField name="Cost per Output Token" type="Number" required>
  The cost in dollars per output token. This is the rate charged by the provider for tokens in the model's responses.
  **Example**: 0.00003 (representing $0.00003 per token)
</ResponseField>

<ResponseField name="Cost per Cache Read Input Token" type="Number">
  The cost in dollars per cached input token. Some providers offer reduced rates for cached requests.
  **Example**: 0.000005 (representing $0.000005 per token)
</ResponseField>

<ResponseField name="Tokenizer Provider" type="Text">
  The provider of the tokenizer used by the model. This is important for accurate token counting and cost estimation.
  Right now, the only supported tokenizers are:
  **Examples**: 
  - "OpenAI" (uses [tiktoken](https://github.com/openai/tiktoken))
  - "Anthropic" (uses [anthropic-tokenizer](https://lunary.ai/anthropic-tokenizer))
</ResponseField>

<ResponseField name="Source" type="Text" required>
  The provider or source of the pricing model. This can be a URL to the model's pricing page or documentation.
  For instance: https://openai.com/api/pricing/
</ResponseField>

## Related Concepts

<CardGroup cols={2}>
  <EvaluationCard />
  <EvaluationTaskCard />
</CardGroup>

## SDK Integration

<CardGroup cols={2}>
  <ModelCard />
</CardGroup>