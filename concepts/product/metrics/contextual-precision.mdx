---
title: "Contextual Precision"
description: "Evaluates whether relevant documents in the retrieval context are ranked higher than irrelevant ones."
---

The **Contextual Precision** metric assesses how well your RAG pipeline’s retriever prioritizes relevant content. Specifically, it checks whether relevant items in the `retrieval_context` are ranked higher than irrelevant ones, based on their contribution to answering the user’s query.

High contextual precision means that the retriever is efficiently surfacing the most useful information near the top.

---

## Evaluation Parameters

To compute the `contextual_precision` metric, the following are required:

- **`input`**: The user’s query.
- **`retrieval_context`**: The list of retrieved documents or nodes, in ranked order.

This setup allows for a rank-sensitive evaluation of retrieval effectiveness.

---

## How Is It Calculated?

The score is calculated as follows:

1. **Relevance Annotation**: An LLM identifies which items in the `retrieval_context` are relevant to the `input`.
2. **Ranking Evaluation**: It checks whether relevant items appear near the top of the list.

The metric is computed using a simplified formula:

$$
\text{Contextual Precision} = \frac{\text{Number of relevant items in top-k}}{k}
$$

Where **k** is a configurable cutoff (e.g., top 5 or top 10). This helps gauge whether the most useful content is easily accessible to the generator.

---

## Related Topics

- [Contextual Relevancy](/concepts/product/metrics/contextual-relevancy)
- [Faithfulness](/concepts/product/metrics/faithfulness)