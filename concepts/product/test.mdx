---
title: "Test"
description: "A set of challenges for evaluating product performance"
icon: "clipboard-list"
iconType: "solid"
---

## What is a Test?

A test in Galtea is a set of challenges designed to evaluate the performance of a [product](/concepts/product). A test file provides simulations of interactions with the product (and, in [quality tests](/concepts/product/test/quality-tests), expected outcomes for each interaction).

## Test Origin

When creating a test in the Galtea dashboard, you'll be asked to specify the test origin:

<CardGroup cols={2}>
  <Card title="Generated" icon="wand-magic-sparkles">
    Galtea will take the ground truth file and generate a set of challenges that will define the test.
  </Card>
  <Card title="Uploaded" icon="file-arrow-up">
    The test is uploaded by you as a complete set of test cases.
  </Card>
</CardGroup>

Your selection will determine whether you need to provide a Ground Truth File or a Test File.

## Test Types

Galtea supports two main types of tests:

<CardGroup cols={2}>
  <Card title="Quality Tests" icon="star" href="/concepts/product/test/quality-tests">
    Tests that evaluate the quality and correctness of outputs
  </Card>
  <Card title="Red Teaming Tests" icon="shield-halved" href="/concepts/product/test/red-teaming-tests">
    Tests that evaluate security, safety, and bias aspects
  </Card>
</CardGroup>

## Using Tests in Evaluations

Tests are used in [evaluation tasks](/concepts/product/evaluation/task) to assess the performance of specific [versions](/concepts/product/version) of your product. 


<Warning>
  The data within the *Test File* should be reused across multiple [evaluations](/concepts/product/evaluation) of distinct [versions](/concepts/product/version) to ensure consistent comparison between different [product](/concepts/product)  [versions](/concepts/product/version). Meaning that distinct [evaluation tasks](/concepts/product/evaluation/task) of different [evaluations](/concepts/product/evaluation) should be composed of the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Warning>

<Note>
  There is no actual need of using the data in the *Test File* to run [evaluation tasks](/concepts/product/evaluation/task), but it is essential to ensure that the multiple [evaluations](/concepts/product/evaluation) that are linked to the same [test](/concepts/product/version) are composed of [evaluation tasks](/concepts/product/evaluation/task) that ran with the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Note>

<Card title="Create an Evaluation" icon="badge-check" iconType="solid" href="/concepts/product/evaluation">
  Learn how to use tests in evaluations
</Card>

## Test Properties

When creating a test in Galtea, you'll need to provide the following information:

<ResponseField name="Test Name" type="Text" required>
  The name of the test. **Example**: "Legal Document Quality Test" or "Customer Support Safety Evaluation"
</ResponseField>

<ResponseField name="Type" type="Enum" required>
  The type of the test. 
  Possible values:
  - [Quality](/concepts/product/test/quality-tests): Tests that evaluate the quality and correctness of outputs
  - [Red Teaming](/concepts/product/test/red-teaming-tests): Tests that evaluate security, safety, and bias aspects
</ResponseField>

<Note>You need to provide **either** a *Ground Truth File* **or** a *Test File*, but not both. Your choice depends on your test creation approach.</Note>

<ResponseField name="Ground Truth File" type="File" required="conditional">
  The reference file used to generate the test. Required if the challenges have to be generated by Galtea. **Example**: A PDF containing a product catalog
</ResponseField>

<ResponseField name="Test File" type="File" required="conditional">
  The file containing the test data: questions and answers, adversarial inputs, etc. Required if uploading a pre-made test. **Example**: A JSON file with a predefined set of test cases
</ResponseField>