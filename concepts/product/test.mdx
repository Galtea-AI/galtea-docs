---
title: "Test"
description: "A set of test cases for evaluating product performance"
icon: "clipboard-list"
iconType: "solid"
---

import SDKTestServiceCard from '/snippets/cards/sdk-test-service-card.mdx';

## What is a Test?

A test in Galtea is a set of test cases designed to evaluate the performance of a [product](/concepts/product). A test file provides simulations of interactions with the product (and, in [quality tests](/concepts/product/test/quality-tests), expected outcomes for each interaction).

## Test Origin

When creating a test in the Galtea dashboard, you'll be asked to specify the test origin:

<CardGroup cols={2}>
  <Card title="Generated" icon="wand-magic-sparkles">
    Galtea will take the knowledge base file and generate a set of test cases that will define the test.
  </Card>
  <Card title="Uploaded" icon="file-arrow-up">
    The test is uploaded by you as a complete set of test cases.
  </Card>
</CardGroup>

Your selection will determine whether you need to provide a Knowledge Base File or a Test File.

<Info>
  More information on how to create tests can be found in the [Quality Tests](/concepts/product/test/quality-tests) and [Red Teaming Tests](/concepts/product/test/red-teaming-tests) sections.
</Info>

## Test Types

Galtea supports two main types of tests:

<CardGroup cols={2}>
  <Card title="Quality Tests" icon="star" href="/concepts/product/test/quality-tests">
    Tests that evaluate the quality and correctness of outputs
  </Card>
  <Card title="Red Teaming Tests" icon="shield-halved" href="/concepts/product/test/red-teaming-tests">
    Tests that evaluate security, safety, and bias aspects
  </Card>
</CardGroup>

## Using Tests in Evaluations

Tests are used in [evaluation tasks](/concepts/product/evaluation/task) to assess the performance of specific [versions](/concepts/product/version) of your product. 


<Warning>
  The data within the *Test File* should be reused across multiple [evaluations](/concepts/product/evaluation) of distinct [versions](/concepts/product/version) to ensure consistent comparison between different [product](/concepts/product)  [versions](/concepts/product/version). Meaning that distinct [evaluation tasks](/concepts/product/evaluation/task) of different [evaluations](/concepts/product/evaluation) should be composed of the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Warning>

<Note>
  There is no actual need of using the data in the *Test File* to run [evaluation tasks](/concepts/product/evaluation/task), but it is essential to ensure that the multiple [evaluations](/concepts/product/evaluation) that are linked to the same [test](/concepts/product/version) are composed of [evaluation tasks](/concepts/product/evaluation/task) that ran with the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Note>

<Card title="Create an Evaluation" icon="badge-check" iconType="solid" href="/concepts/product/evaluation">
  Learn how to use tests in evaluations
</Card>

## SDK Integration

<SDKTestServiceCard />

## Test Properties

When creating a test in Galtea, you'll need to provide the following information:

<ResponseField name="Test Name" type="Text" required>
  The name of the test. **Example**: "Legal Document Quality Test" or "Customer Support Safety Evaluation"
</ResponseField>

<ResponseField name="Type" type="Enum" required>
  The type of the test. 
  Possible values:
  - [Quality](/concepts/product/test/quality-tests): Tests that evaluate the quality and correctness of outputs
  - [Red Teaming](/concepts/product/test/red-teaming-tests): Tests that evaluate security, safety, and bias aspects
</ResponseField>

<Note>You need to provide **either** a *Knowledge Base File* **or** a *Test File*, but not both. Your choice depends on your test creation approach.</Note>

<ResponseField name="Knowledge Base File" type="File" required="conditional">
  The path to a local file (e.g., PDF, TXT, JSON, HTML, Markdown) containing the knowledge base. This file is uploaded to Galtea, which then generates test cases based on its content. Required if the test cases are to be generated by Galtea. **Example**: "path/to/your/knowledge_base.pdf"
</ResponseField>

<ResponseField name="Language" type="Text">
  The language for generating synthetic test cases if `Knowledge Base File` is provided (e.g., 'english', 'spanish'). This should be the English name of the language. If not provided, Galtea attempts to infer the language from the knowledge base file. Supported languages include English, Spanish, Catalan, French, German, Portuguese, Italian, Dutch, Polish, Chinese, Korean, and Japanese.
  <Note>This field only applies if tests are generated by Galtea (using `Knowledge Base File`).</Note>
</ResponseField>

<ResponseField name="Variants" type="list[string]">
  A list of strings specifying modifications to apply to original queries for synthetic data generation (e.g., 'paraphrased', 'typos', 'incorrect'). This is applicable only if `Knowledge Base File` is used. Refer to the [SDK documentation for test creation](/sdk/api/test/service#param-variants) for a comprehensive list of available variants.
  <Note>Using variants will increase the number of generated test cases and consequently the cost of test generation, unless a *maximum number of test cases* is provided.</Note>
</ResponseField>

<ResponseField name="Max Test Cases" type="int">
  An optional integer to limit the maximum number of test cases generated by Galtea when `Knowledge Base File` is provided. This helps control the size of the test dataset and associated costs.
</ResponseField>

<ResponseField name="Test File" type="File" required="conditional">
  The path to a local CSV file containing predefined test cases. This file is uploaded to Galtea. Required if you are providing your own set of test cases instead of having Galtea generate them. **Example**: "path/to/your/test_file.csv"
</ResponseField>