---
title: "Test"
description: "A set of test cases for evaluating product performance"
icon: "clipboard-list"
iconType: "solid"
---

import SDKTestServiceCard from '/snippets/cards/sdk-test-service-card.mdx';

## What is a Test?

A test in Galtea is a set of test cases designed to evaluate the performance of a [product](/concepts/product). A test file provides simulations of interactions with the product (and, in [quality tests](/concepts/product/test/quality-tests), expected outcomes for each interaction).

## Test Origin

When creating a test in the Galtea dashboard, you'll be asked to specify the test origin:

<CardGroup cols={2}>
  <Card title="Generated" icon="wand-magic-sparkles">
    Galtea will take the knowledge base file and generate a set of test cases that will define the test.
  </Card>
  <Card title="Uploaded" icon="file-arrow-up">
    The test is uploaded by you as a complete set of test cases.
  </Card>
</CardGroup>

Your selection will determine whether you need to provide a Knowledge Base File or a Test File.

<Info>
  More information on how to create tests can be found in the [Quality Tests](/concepts/product/test/quality-tests) and [Red Teaming Tests](/concepts/product/test/red-teaming-tests) sections.
</Info>

## Test Types

Galtea supports two main types of tests:

<CardGroup cols={2}>
  <Card title="Quality Tests" icon="star" href="/concepts/product/test/quality-tests">
    Tests that evaluate the quality and correctness of outputs
  </Card>
  <Card title="Red Teaming Tests" icon="shield-halved" href="/concepts/product/test/red-teaming-tests">
    Tests that evaluate security, safety, and bias aspects
  </Card>
</CardGroup>

## Using Tests in Evaluations

Tests are used in [evaluation tasks](/concepts/product/evaluation/task) to assess the performance of specific [versions](/concepts/product/version) of your product. 


<Warning>
  The data within the *Test File* should be reused across multiple [evaluations](/concepts/product/evaluation) of distinct [versions](/concepts/product/version) to ensure consistent comparison between different [product](/concepts/product)  [versions](/concepts/product/version). Meaning that distinct [evaluation tasks](/concepts/product/evaluation/task) of different [evaluations](/concepts/product/evaluation) should be composed of the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Warning>

<Note>
  There is no actual need of using the data in the *Test File* to run [evaluation tasks](/concepts/product/evaluation/task), but it is essential to ensure that the multiple [evaluations](/concepts/product/evaluation) that are linked to the same [test](/concepts/product/version) are composed of [evaluation tasks](/concepts/product/evaluation/task) that ran with the same [input](/concepts/product/evaluation/task#param-input) and [context](/concepts/product/evaluation/task#param-context).
</Note>

<Card title="Create an Evaluation" icon="badge-check" iconType="solid" href="/concepts/product/evaluation">
  Learn how to use tests in evaluations
</Card>

## SDK Integration

<SDKTestServiceCard />

## Test Properties

When creating a test in Galtea, you'll need to provide the following information:

<ResponseField name="Test Name" type="Text" required>
  The name of the test. **Example**: "Legal Document Quality Test" or "Customer Support Safety Evaluation"
</ResponseField>

<ResponseField name="Type" type="Enum" required>
  The type of the test. 
  Possible values:
  - [Quality](/concepts/product/test/quality-tests): Tests that evaluate the quality and correctness of outputs
  - [Red Teaming](/concepts/product/test/red-teaming-tests): Tests that evaluate security, safety, and bias aspects
</ResponseField>

<Note>You need to provide **either** a *Knowledge Base File* **or** a *Test File*, but not both. Your choice depends on your test creation approach.</Note>

<ResponseField name="Knowledge Base File" type="File" required="conditional">
  The reference file used to generate the test. Required if the test cases have to be generated by Galtea. **Example**: A PDF containing a product catalog
</ResponseField>

<ResponseField name="Language" type="Text">
  The language for generating synthetic test cases if `ground_truth_file_path` is provided (e.g., 'english', 'spanish'). This should be the English name of the language. Defaults to the language inferred from the ground truth file. Supported languages are listed in the [SDK documentation for test creation](/sdk/api/test-service#create-test).
  <Note>This field only applies if tests are generated by Galtea (using `ground_truth_file_path`).</Note>
</ResponseField>

<ResponseField name="Variants" type="list[string]">
  A list of strings specifying modifications to apply to original queries for synthetic data generation (e.g., 'paraphrased', 'typos', 'incorrect'). This is applicable only if `ground_truth_file_path` is used. Refer to the [SDK documentation for test creation](/sdk/api/test-service#create-test) for a comprehensive list of available variants.
  <Note>Using variants will increase the number of generated test cases and consequently the cost of test generation. Unles a *maximum number of test cases* is provided.</Note>
</ResponseField>

<ResponseField name="Max Test Cases" type="int">
  An optional integer to limit the maximum number of test cases generated by Galtea when `ground_truth_file_path` is provided. This helps control the size of the test dataset and associated costs.
</ResponseField>

<ResponseField name="Test File" type="File" required="conditional">
  The file containing the test data (the test cases). Essentially the "questions" and "answers", adversarial inputs, etc. Required if uploading a pre-made test. **Example**: A CSV file with a predefined set of test cases.
</ResponseField>