---
title: 'Test Service'
description: "Exploring the Test Service API in the Galtea SDK"
icon: "clipboard-list"
iconType: "solid"
---

The Test Service in the Galtea SDK allows you to manage [tests](/concepts/product/test) for evaluating your products.
This Service is exposed by the `galtea.tests` object and we will further explore its API down below.

<Info>
  Remember that we will be using the `galtea` object. More information [here](/sdk/api/galtea).
</Info>

## Create Test

This method allows you to create a test for your product.

```python
test = galtea.tests.create(
    name="example-test-tutorial",
    type="QUALITY",
    product_id="YOUR_PRODUCT_ID",
    ground_truth_file_path="path/to/knowledge_file.pdf",
    language='english',
    variants=["paraphrased", "typos", "incorrect"],
    max_test_cases=100
)
```

<Info>
  See a complete example of creating **custom tests** in our [Create a Custom Test example](/sdk/examples/create-test).
</Info>

<ResponseField name="name" type="string" required>
  The name of the test.
</ResponseField>

<ResponseField name="type" type="string" required>
  The type of test (e.g., [QUALITY](/concepts/product/test/quality-tests), [RED_TEAMING](/concepts/product/test/red-teaming-tests)).
</ResponseField>

<ResponseField name="product_id" type="string" required>
  The ID of the product you want to evaluate.
</ResponseField>

<Note>
  You must provide either `test_file_path` or `ground_truth_file_path`, but not both.
</Note>

<ResponseField name="ground_truth_file_path" type="string">
  The path to the knowledge file (pdf format) in which We will find the information the source of truth for the model answers.
  We have to wait for the platform to generate a synthetic dataset based on the ground_truth provided, so we need to wait for the test to be ready before we can use it.

  <Note>
    The ground truth is also referenced as the knowledge base.
  </Note>
</ResponseField>

<ResponseField name="language" type="string">
  The language for generating synthetic test cases if `ground_truth_file_path` is used (e.g., 'english', 'spanish'). This should be the English name of the language. If not provided, Galtea attempts to infer the language from the ground truth file. Supported languages include English, Spanish, French, German, Portuguese, Italian, Dutch, Polish, Chinese, Korean, and Japanese.
  <Note>
    This field only makes sense if the test is generated by Galtea.
  </Note>
</ResponseField>

<ResponseField name="variants" type="list[string]">
  A list of strings specifying modifications to apply to original queries for synthetic data generation (e.g., 'paraphrased', 'typos', 'incorrect'). This is applicable only if `ground_truth_file_path` is used. Available variants include: `paraphrased`, `expanded_question`, `specific_focus_question`, `ambiguous`, `incorrect`, `incomplete`, `typos`, `slang`, `abbreviations`, `unconventional_phrasing`, `combined_topics`, `novel_phrasing`, `hypothetical_scenarios`, `informal`, `linguistic_diverse`, `typographic_error`, `cognitively_diverse`.
  <Note>
    Using variants will increase the number of generated test cases and consequently the cost of test generation.
  </Note>
</ResponseField>

<ResponseField name="max_test_cases" type="int">
  An optional integer to limit the maximum number of test cases generated by Galtea if `ground_truth_file_path` is used. This helps control the size of the test dataset and associated costs.
</ResponseField>

<ResponseField name="test_file_path" type="string">
  The path to the custom test file.
  This file should contain the test cases you want to evaluate.
  If given, the platform won't generate a synthetic dataset based on the ground_truth provided, so we can use the test immediately.
</ResponseField>

## Listing Tests

This method allows you to list all tests associated with a specific product.

```python
tests = galtea.tests.list(product_id="YOUR_PRODUCT_ID")
```

<ResponseField name="product_id" type="string" required>
  The ID of the product for which you want to list tests.
</ResponseField>

<ResponseField name="offset" type="int">
  The number of tests to skip before starting to collect the result set.
</ResponseField>

<ResponseField name="limit" type="int">
  The maximum number of tests to return.
</ResponseField>

## Retrieving Test

This method allows you to retrieve a specific test by its ID.

```python
test = galtea.tests.get(test_id="YOUR_TEST_ID")
```

<ResponseField name="test_id" type="string" required>
  The ID of the test you want to retrieve.
</ResponseField>

## Retrieving Test By Name
This method allows you to retrieve a specific test by its name.


```python
test = galtea.tests.get_by_name(product_id="YOUR_PRODUCT_ID", name="YOUR_TEST_ID")
```

<ResponseField name="product_id" type="string" required>
  The ID of the product for which you want to retrieve the test.
</ResponseField>

<ResponseField name="name" type="string" required>
  The name of the test you want to retrieve.
</ResponseField>

<ResponseField name="type" type="string">
  The type of test (e.g., [QUALITY](/concepts/product/test/quality-tests), [RED_TEAMING](/concepts/product/test/red-teaming-tests)).
</ResponseField>

## Deleting Test

This method allows you to delete a specific test by its ID.

```python
galtea.tests.delete(test_id="YOUR_TEST_ID")
```

<ResponseField name="test_id" type="string" required>
  The ID of the test you want to delete.
</ResponseField>

