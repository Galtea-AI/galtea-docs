---
title: 'Create Test'
description: "Create a test for your product."
---

## Returns
Returns a [Test](/concepts/product/test) object for the given parameters.

## Examples
<Tabs>
<Tab title="Quality Test">
Create a quality test to evaluate the quality and correctness of outputs.
```python
test = galtea.tests.create(
    name="example-test-tutorial",
    type="QUALITY",
    product_id="YOUR_PRODUCT_ID",
    ground_truth_file_path="path/to/knowledge_file.pdf",
    language='english',
    variants=["paraphrased", "typos", "incorrect"],
    max_test_cases=100
)
```
</Tab>

<Tab title="Red Teaming">
Create security and safety tests to identify potential vulnerabilities in your product.

```python
test = galtea.tests.create(
    name="security-red-team-test",
    type="RED_TEAMING",
    product_id="YOUR_PRODUCT_ID",
    variants=["harmful_content", "bias", "privacy"],
    strategies=["jailbreaking", "prompt_injection"],
    max_test_cases=50
)
```

</Tab>

<Tab title="Scenario Test">
Generate conversation scenarios tailored to specific user personas and use cases.

```python
test = galtea.tests.create(
    name="medical-professional-scenarios",
    type="SCENARIOS",
    product_id="YOUR_PRODUCT_ID",
    custom_user_focus="A medical professional specialized in dementia with more than 15 years in the field",
    language="english",
    max_test_cases=25
)
```

</Tab>

<Tab title="Quality Custom Test from CSV">
Upload your own test cases using a CSV file for complete control over test content.

```python
test = galtea.tests.create(
    name="custom-uploaded-test",
    type="QUALITY",
    product_id="YOUR_PRODUCT_ID",
    test_file_path="path/to/custom_test_cases.csv"
)
```

<Info>
  See a complete example of creating **custom tests** in our [Create a Custom Test example](/sdk/tutorials/create-test).
</Info>
</Tab>
</Tabs>

## Parameters
<ResponseField name="name" type="string" required>
  The name of the test.
</ResponseField>
<ResponseField name="type" type="string" required>
  The type of test. Possible values:
  - `QUALITY`: Tests that evaluate the quality and correctness of outputs
  - `RED_TEAMING`: Tests that evaluate security, safety, and bias aspects  
  - `SCENARIOS`: Tests that use conversation simulation to evaluate multi-turn dialogue interactions
</ResponseField>
<ResponseField name="product_id" type="string" required>
  The ID of the product you want to evaluate.
</ResponseField>
<ResponseField name="ground_truth_file_path" type="string" optional>
  Path to a local file containing the knowledge base. This file is uploaded to Galtea, which then generates test cases based on its content.
  <Note>
    Supported formats include `.pdf`, `.txt`, `.json`, `.html`, `.md`, and `.zip`. Upload a `.zip` archive to generate test cases from multiple documents at once.
  </Note>
</ResponseField>
<ResponseField name="few_shot_examples" type="string" optional>
  Optional few-shot examples to provide more context to our system about how the test cases should be generated. This can help our system better understand the expected format and style wanted for the test cases.
  **Example**: 
  ```
  Q: What is the capital of France?
  A: The capital of France is Paris.
  Q: What is the capital of Germany?
  A: The capital of Germany is Berlin.
  ```
  <Note>This field only applies if tests are generated by Galtea and are of type `QUALITY`.</Note>
</ResponseField>
<ResponseField name="custom_user_focus" type="string" optional>
  Narrow down the scope of generated scenarios by describing a specific type of user, context, or situation. This helps ensure test cases align with your most relevant goals and flows.
  Example: "A medical professional specialized in dementia with more than 15 years on the field."
  <Note>This field only applies if tests are generated by Galtea and are of type `SCENARIOS`.</Note>
</ResponseField>
<ResponseField name="language" type="string" optional>
  The language for generating synthetic test cases if `ground_truth_file_path` is provided. Defaults to the language detected in the ground truth file. If provided, it should be written in English and be a valid language name from the ISO 639 standard (e.g., "english", "spanish", "french"). More information can be found at [https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes).
</ResponseField>
<ResponseField name="variants" type="list[string]" optional>
  A list of strings that specifies how to generate test cases related to its objectives. The meaning of this parameter depends on the `type` of the test:
  - **For `QUALITY` tests**: Specifies the **Evolutions** to apply to the base test cases (e.g., `["paraphrased", "typos"]`). See the full list of available evolutions in the [Quality Test Evolutions documentation](/concepts/product/test/quality-evolutions).
  - **For `RED_TEAMING` tests**: Specifies the **Threat** category to generate test cases for (e.g., `["data_leakage"]`). See the full list in the [Red Teaming Threats documentation](/concepts/product/test/red-teaming-threats).
</ResponseField>
<ResponseField name="strategies" type="list[string]" optional>
  A list of strings that specifies how to generate test cases related to its style. 
  - **For `RED_TEAMING` tests**: Strategies are techniques for modifying or obfuscating prompts generated for each threat (as specified in `variants` for Red Teaming tests). See the full list of [red teaming strategies](/concepts/product/test/red-teaming-strategies).
  - **For `SCENARIOS` tests**: Strategies define the conversation style. Currently `written` and `spoken` are supported, which influence the tone and formality of the generated dialogues. If not specified, the default strategy is `written`.
</ResponseField>
<ResponseField name="max_test_cases" type="int" optional>
  An optional integer to limit the maximum number of test cases generated by Galtea when `ground_truth_file_path` is used.
</ResponseField>
<ResponseField name="test_file_path" type="string" optional>
  Path to a local CSV file containing predefined test cases. This file is uploaded to Galtea.
  
  **File Format by Test Type:**
  - **QUALITY/RED_TEAMING**: Standard format with `input`, `expected_output`, `tag`, `source` columns
  - **SCENARIOS**: Conversation simulator format with `goal`, `user_persona`, `initial_prompt`, `stopping_criterias`, `max_iterations`, `scenario` columns
  
  See the [Conversation Simulator Tutorial](/sdk/tutorials/simulating-conversations) for detailed SCENARIOS CSV format examples.
</ResponseField>
