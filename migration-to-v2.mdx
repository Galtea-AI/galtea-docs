# Migrating to Galtea SDK v2.0

Welcome to Galtea SDK v2.0! This version introduces major improvements, including a new session-based evaluation workflow and simplifications to the existing test-based workflow.

This guide will walk you through the necessary changes to update your SDK v1.x integrations and introduce you to the new features available in v2.0.

## Part 1: Migrating Your Existing Workflow (Test-Case-Based Evaluation)

The core workflow for running predefined tests against a version has been streamlined.

### Key Changes for Test-Based Evaluations

1.  **Simplified Version Creation**: The `galtea.versions.create()` method now accepts all properties as direct keyword arguments, removing the need for the `optional_props` dictionary.

2.  **Implicit Evaluation Creation**: You no longer need to explicitly call `galtea.evaluations.create()` before creating evaluation tasks. An `Evaluation` (which links a `Test` and a `Version`) is now created automatically by the backend when the first evaluation task for that pair is submitted.

3.  **`evaluation_tasks.create()` Signature Change**: The `evaluation_id` parameter is removed and replaced by a required `version_id`. The backend will automatically determine the correct evaluation to associate the task with.

### Migration Diff: Test-Case Workflow

Here’s a side-by-side comparison of a typical v1 script and its direct v2 equivalent.

#### ❌ SDK v1.x (Old Way)
```python
from galtea import Galtea
galtea = Galtea(api_key="...")

# 1. Create version with optional_props dictionary
version = galtea.versions.create(
    name="v1.0-summarizer",
    product_id="YOUR_PRODUCT_ID",
    optional_props={
      "description": "Old version using gpt-3.5",
      "model_id": "gpt-3.5-turbo"
    }
)

# 2. Explicitly create an Evaluation
evaluation = galtea.evaluations.create(
    test_id="YOUR_TEST_ID",
    version_id=version.id
)

# 3. Create tasks using evaluation_id
galtea.evaluation_tasks.create(
    evaluation_id=evaluation.id,
    metrics=["your_metric"],
    test_case_id="YOUR_TEST_CASE_ID",
    actual_output="This is the model's output."
)
```

#### ✅ SDK v2.0 (New Way)
```python
from galtea import Galtea
galtea = Galtea(api_key="...")

# 1. Create version with direct keyword arguments
version = galtea.versions.create(
    name="v2.0-summarizer",
    product_id="YOUR_PRODUCT_ID",
    description="New version using gpt-4",
    model_id="gpt-4"
)

# 2. Skip explicit evaluation creation (it's automatic!)

# 3. Create tasks using version_id
galtea.evaluation_tasks.create(
    version_id=version.id,
    metrics=["your_metric"],
    test_case_id="YOUR_TEST_CASE_ID",
    actual_output="This is the model's output."
)
```

### Summary of Actions for Migration

1.  In `galtea.versions.create()` calls, remove the `optional_props` dictionary and pass its contents as direct keyword arguments.
2.  **Remove** all calls to `galtea.evaluations.create()`.
3.  In `galtea.evaluation_tasks.create()` calls, **remove** the `evaluation_id` parameter and **add** the `version_id` parameter.

---

## Part 2: What's New in v2.0 - The Session-Based Workflow

SDK v2.0 introduces a powerful new way to log and evaluate multi-turn conversations through **Sessions** and **Inference Results**. This is ideal for monitoring production traffic or evaluating complex, interactive scenarios.

### New Concepts

*   **Session**: A container for a sequence of interactions (a conversation) between a user and your AI product. You can create a session using `galtea.sessions.create()`.
*   **Inference Result**: A single turn within a session, containing the `input` and `output`. You log these using `galtea.inference_results.create()`.
*   **`evaluation_tasks.create_from_session()`**: A new method to run evaluations on all inference results within a given session. This allows for easy batch evaluation of entire conversations.

### Example of the New Session-Based Workflow

This workflow is entirely new and does not directly replace the test-based workflow. You can use it alongside your existing tests.

```python
# SDK v2.0 New Workflow Example
from galtea import Galtea

galtea = Galtea(api_key="YOUR_API_KEY")

YOUR_PRODUCT_ID = "your_product_id"
YOUR_VERSION_ID = "your_version_id"
YOUR_METRIC_NAME = "your_metric_name"

# 1. Create a Session to group a conversation
session = galtea.sessions.create(
    version_id=YOUR_VERSION_ID
)
print(f"Created Session: {session.id}")

# 2. Log inference results (conversation turns) to the session
galtea.inference_results.create(
    session_id=session.id,
    input="What's your return policy?",
    output="Our return policy allows returns within 30 days of purchase."
)
galtea.inference_results.create(
    session_id=session.id,
    input="What if I lost the receipt?",
    output="A proof of purchase is required for all returns."
)
print(f"Stored 2 inference results in session {session.id}")

# 3. When ready, create evaluation tasks for the entire session
evaluation_tasks = galtea.evaluation_tasks.create_from_session(
    session_id=session.id,
    metrics=[YOUR_METRIC_NAME]
)
print(f"Submitted {len(evaluation_tasks)} evaluation tasks for session {session.id}")
```

### Benefits of the New Workflow

*   **Track Full Conversations**: Accurately log and analyze multi-turn user interactions.
*   **Production Monitoring**: Easily send production data to Galtea for continuous evaluation.
*   **Batch Evaluation**: Evaluate an entire conversation with a single command.

If you have any questions or encounter any issues during migration, please don't hesitate to reach out to our support team at [support@galtea.ai](mailto:support@galtea.ai).