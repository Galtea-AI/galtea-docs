---
title: "Quickstart"
description: "All you need to get started"
icon: "rocket"
---

import ProductCard from '/snippets/cards/product-card.mdx';
import VersionCard from '/snippets/cards/version-card.mdx';
import TestCard from '/snippets/cards/test-card.mdx';
import EvaluationCard from '/snippets/cards/evaluation-card.mdx';
import EvaluationTaskCard from '/snippets/cards/evaluation-task-card.mdx';
import MetricTypeCard from '/snippets/cards/metric-type-card.mdx';

This guide will walk you through the essential steps to begin evaluating and monitoring the reliability of your AI products with Galtea.

## Evaluation Workflow Overview

Evaluating AI products with Galtea follows this pattern:

<Steps>
  <Step title="Create a Product">
    Define what functionality or service you want to evaluate
  </Step>
  <Step title="Register a Version">
    Document the specific implementation of your product
  </Step>
  <Step title="Create a Test">
    Define a set of challenges to evaluate your product's performance
  </Step>
  <Step title="Define Metrics">
    Select or create criteria to assess outputs
  </Step>
  <Step title="Run Evaluations">
    Test your product and analyze the results
  </Step>
</Steps>

Let's go through each step in more detail.

## 1. Creating a Product

The first step in tracking the quality and reliability of your AI product is to create a [product](/concepts/product) in the Galtea dashboard.

![login to the platform](/images/login.png)

Navigate to **[Products](https://platform.galtea.ai/products) > Create New Product** and complete the product onboarding form. The product description is particularly important as it may be used during the generation of synthetic test data.

![product onboarding](/images/product-onboarding.png)

<Note>
  Products can only be created through the web platform, not the SDK. For detailed information about product properties, see the [Product](/concepts/product) documentation.
</Note>

## 2. Install the SDK and Connect

After creating your product, we recommend to use the [Galtea SDK](/sdk) to programmatically interact with the platform.

<Steps>
  <Step title="Get your API key">
    In the [Galtea platform](https://platform.galtea.ai/), navigate to **[Settings](https://platform.galtea.ai/settings) > Generate API Key**
    
    ![Get API key](/images/api-key.png)
  </Step>
  <Step title="Install the SDK">
    ```sh
    pip install galtea
    ```
  </Step>
  <Step title="Connect to the platform">
    ```python
    from galtea import Galtea
    
    # Initialize with your API key
    galtea = Galtea(api_key="YOUR_API_KEY")
    
    # List your products to verify connection
    products = galtea.products.list()
    ```
  </Step>
</Steps>

<Card title="SDK Installation Guide" icon="cube" href="/sdk/installation">
  For detailed installation instructions and requirements
</Card>

## 3. Register a Version

One of the key advantages of the [Galtea platform](https://platform.galtea.ai/) is the ability to track and compare different [versions](/concepts/product/version) of your AI product. A version captures the specific implementation details such as prompts, model parameters, or RAG configurations.

```python
version = galtea.versions.create(
    name="v1.0",
    product_id="YOUR_PRODUCT_ID",
    optional_props={
        "description": "Initial version"
        # Add other metadata like system_prompt, endpoint, etc.
    }
)
```

<Info>
  You can create versions using either the SDK (as shown above) or directly through the [Galtea platform](https://platform.galtea.ai/) dashboard.
</Info>

<Card title="Version Service API" icon="swatchbook" href="/sdk/api/version-service">
  Learn about all version properties and management capabilities
</Card>

## 4. Create a Test

To compare the reliability of different versions, you need to subject each version to the same tests. Galtea supports two test types:

<CardGroup cols={2}>
  <Card title="Quality Tests" icon="star" href="/concepts/product/test/quality-tests">
    Tests that evaluate accuracy and correctness
  </Card>
  <Card title="Red Teaming Tests" icon="shield-halved" href="/concepts/product/test/red-teaming-tests">
    Tests that evaluate security and safety aspects
  </Card>
</CardGroup>

You can either upload your own test file or have Galtea generate tests from a ground truth document:

```python
test = galtea.tests.create(
    name="example-test",
    type="QUALITY",
    product_id="YOUR_PRODUCT_ID",
    test_file_path="path/to/your/test_file.csv"
    # Or use ground_truth_file_path="path/to/knowledge_file.pdf"
)
```

<Info>
  Tests can be created using either the SDK (as shown above) or directly through the [Galtea platform](https://platform.galtea.ai/) dashboard.
</Info>

<Card title="Create a Custom Test" icon="clipboard-list" href="/sdk/examples/create-test">
  See complete examples of creating and uploading tests
</Card>

## 5. Define Metrics

Metrics in Galtea define the criteria by which your product's outputs will be evaluated. These [metric types](/concepts/metric-type) can be reused across different evaluations.

```python
metric = galtea.metrics.create(
    name="accuracy_v0",
    criteria="Determine whether the actual output is equivalent to the expected output."
)
```

<Info>
  Metric types can be created using either the SDK (as shown above) or directly through the [Galtea platform](https://platform.galtea.ai/metrics) dashboard.
</Info>

<Card title="Metrics Service API" icon="function" href="/sdk/api/metrics-service">
  Learn about creating and managing evaluation metrics
</Card>

## 6. Run Evaluations

Finally, you're ready to launch an [evaluation](/concepts/product/evaluation) to assess how well your product version performs against the test challenges:

```python
# Create an evaluation
evaluation = galtea.evaluations.create(
    test_id="YOUR_TEST_ID", 
    version_id="YOUR_VERSION_ID"
)

# Run an evaluation task
galtea.evaluation_tasks.create(
    metrics=["accuracy_v0"],
    evaluation_id=evaluation.id,
    input="What is the capital of Spain?",
    actual_output="Barcelona",  # From your AI product
    expected_output="Madrid"    # From test definition
)
```

<Info>
  Evaluations can be created using either the SDK or the [Galtea platform](https://platform.galtea.ai/) dashboard, but evaluation tasks can only be created through the SDK.
</Info>

<Note>
  For real evaluations, you'll typically run your AI product against all inputs in your test set. The platform will asynchronously evaluate responses and make results available through the dashboard or SDK. For more information, see [evaluation tasks](/concepts/product/evaluation/task).
</Note>

<Card title="Run Evaluations" icon="badge-check" href="/sdk/examples/create-evaluation">
  See complete examples of running and analyzing evaluations
</Card>

## View Results

You can view evaluation results through the SDK or on the platform:

```python
# Retrieve evaluation tasks
tasks = galtea.evaluation_tasks.list(evaluation.id)
if tasks:
    result = galtea.evaluation_tasks.get(tasks[0].id)
    print(f"Score: {result.score}")
    print(f"Reason: {result.reason}")
```

For richer analysis and comparisons between versions, visit the Analytics section of your product in the [Galtea platform](https://platform.galtea.ai/).

## Next Steps

Congratulations! You've completed your first evaluation with Galtea. For more detailed information:

<CardGroup cols={3}>
    <ProductCard />
    <VersionCard />
    <TestCard />
    <EvaluationCard />
    <EvaluationTaskCard />
    <MetricTypeCard />
</CardGroup>

If you have any questions, contact us at [support@galtea.ai](mailto:support@galtea.ai).